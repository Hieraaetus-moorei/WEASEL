{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "This notebook will guilde you to train a customised YOLO model with your own dataset (e.g. tank images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Environment setting up\n",
    "\n",
    "_Go install cuda if you have nvdia GPU since it will accelerate your training process *a lot*_\n",
    "\n",
    "Then you can go to [pyTorch official website](https://pytorch.org/get-started/locally/) to get the proper downloading command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Download pyTorch for windows with cuda\n",
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 \n",
    "\n",
    "# Install YOLO\n",
    "!pip install ultralytics\n",
    "\n",
    "# setting up the directory for YOLO training\n",
    "import os\n",
    "\n",
    "root_dir = 'tank_imgs'\n",
    "if not os.path.exists(root_dir):\n",
    "    os.makedirs(root_dir)\n",
    "\n",
    "subdirs = ['train', 'valid']\n",
    "for subdir in subdirs:\n",
    "    subdir_path = os.path.join(root_dir, subdir)\n",
    "    if not os.path.exists(subdir_path):\n",
    "        os.makedirs(subdir_path)\n",
    "\n",
    "for subdir in subdirs:\n",
    "    for subsubdir in ['images', 'labels']:\n",
    "        subsubdir_path = os.path.join(root_dir, subdir, subsubdir)\n",
    "        if not os.path.exists(subsubdir_path):\n",
    "            os.makedirs(subsubdir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data organisation for training\n",
    "Before training your own customised YOLO model, put the:\n",
    "* training images into `images` folder inside the `train` folder under `tank_imgs` directory\n",
    "* labels for training images into `labels` folder at the same directory\n",
    "* validation images into `images` folder inside the `valid` folder under `tank_imgs` directory\n",
    "* labels for validation images into `labels` folder at the same directory\n",
    "\n",
    "The training/validating ratio can be decided by yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training part\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# the directory you want to put the yolo model in\n",
    "dir = './'\n",
    "# you can change the yolo versioin if you see fit\n",
    "# we used nano model because it would later be deployed into Donkey Car's Raspberry Pi, which has limited calculation power\n",
    "model = YOLO(f'{dir}/yolov8n.pt')\n",
    "\n",
    "# start training\n",
    "results = model.train(\n",
    "    data = './weasel.yaml', # yaml file's directory and its name\n",
    "    # imgsz=512, # input image size, default: 640\n",
    "    epochs = 100,\n",
    "    patience = 20, # awaiting n epochs, break if not improved\n",
    "    batch = 16,\n",
    "    project = 'weasel', # customised project name\n",
    "    name = 'exp0' # customised name for this training\n",
    ")\n",
    "\n",
    "# After the long training done, you got your customised YOLO model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Converting the model into onnx format\n",
    "\n",
    "ONNX is a light-weight format with compromised accuracy and fast inference speed\n",
    "Since the calculation power of Raspberry Pi is limited, while real-time inference is neccessary for our WEASEL, onnx plays a crucial role therefore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "\n",
    "model_name = 'yolov8m' #@param [\"yolov8n\", \"yolov8s\", \"yolov8m\", \"yolov8l\", \"yolov8x\"]\n",
    "input_width = 640 #@param {type:\"slider\", min:32, max:4096, step:32}\n",
    "input_height = 480 #@param {type:\"slider\", min:32, max:4096, step:32}\n",
    "optimize_cpu = False\n",
    "\n",
    "model = YOLO(f'{model_name}.pt') \n",
    "# If you don't have a Nvidia GPU, set `optimize_cpu = True` to optimize for CPU inference\n",
    "model.export(format = 'onnx', imgsz = [input_height, input_width], optimize = optimize_cpu)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
